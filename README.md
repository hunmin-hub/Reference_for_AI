# AI 관련 학습 Reference 모음
---
---

### 1. 선형 회귀 모델에서 '선형'이 의미하는 것은 무엇인가?   
[링크](https://brunch.co.kr/@gimmesilver/18)   
~~~
1. 선형은 1차 다항식만을 의미하는 것이 아니다.
2. 선형과 비선형
~~~

***

### 2. 활성화 함수(Activation Function)
[링크](https://m.blog.naver.com/worb1605/2211879498281)   
~~~
활성화 함수란 무엇인가?
활성화 함수의 사용하는 이유
~~~
 
***

### 3. 모수, 큰 수의 법칙, 그리고 중심극한정리
[링크](https://chukycheese.github.io/data%20science/parameter-clt/)   
~~~
모수 (Parameter)
큰 수의 법칙 (Law of Large Numbers)
중심극한정리 (Central Limit Theorem)
~~~
 
***

### 4. Gradient Descent (경사하강법)
[링크](https://angeloyeo.github.io/2020/08/16/gradient_descent.html)   
~~~
Gradient Descent (경사하강법)
~~~
 
***

### 5. 연속확률분포에서 확률 밀도함수가 가지는 의미
[링크](https://velog.io/@groovallstar/%ED%99%95%EB%A5%A0-%EB%B6%84%ED%8F%AC-%ED%95%A8%EC%88%98%EC%99%80-%ED%99%95%EB%A5%A0-%EB%B0%80%EB%8F%84-%ED%95%A8%EC%88%98%EC%9D%98-%EC%9D%98%EB%AF%B8)   
~~~
연속확률분포
확률 밀도함수가 가지는 의미(=왜 적분을 해야하는가?)
~~~
 
***

### 6. 확률질량함수와 확률밀도함수
[링크](https://bskyvision.com/387)   
~~~
이산확률변수 와 연속확률변수
확률질량함수와 확률밀도함수
질량과 밀도의 의미
~~~
 
***

### 7. 역전파 (Backpropagation)
[링크](https://bskyvision.com/718?category=635506)   
~~~
역전파를 통해 딥러닝 모델 학습 방법
~~~
 
***

### 8. 몬테카를로 시뮬레이션 (Monte carlo simulation)   
[링크](https://losskatsu.github.io/statistics/mc-simulation/#%EB%AA%AC%ED%85%8C%EC%B9%B4%EB%A5%BC%EB%A1%9C-%EC%8B%9C%EB%AE%AC%EB%A0%88%EC%9D%B4%EC%85%98monte-carlo-simulation-%EA%B8%B0%EC%B4%88)   
~~~
몬테카를로 시뮬레이션   
~~~
 
***

### 9. 최대가능도 추정법
   
[1] 최대가능도 추정법과 예제   
[링크](https://datascienceschool.net/02%20mathematics/09.02%20%EC%B5%9C%EB%8C%80%EA%B0%80%EB%8A%A5%EB%8F%84%20%EC%B6%94%EC%A0%95%EB%B2%95.html)   
[2] 최대가능도 함수(=우도 함수)란?   
[링크](https://m.blog.naver.com/mykepzzang/221568285099)   
[3] 최대가능도 함수의 시각화   
[링크](https://jjangjjong.tistory.com/41) 
[4] 최대가능도 추정법(MLE, 정규분포 가정)의 구현   
[링크](https://yamalab.tistory.com/94) 
[5] 최대가능도 추정법(MLE) -> 베르누이 분포, 카테고리 분포, 정규분포의 구현   
[링크](https://namyoungkim.github.io/statistics/2017/09/17/probability/) 
~~~
최대가능도 추정법
~~~
 
***

---
---
