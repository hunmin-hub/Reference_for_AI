# AI 관련 학습 Reference 모음
---
---

### 1. 선형 회귀 모델에서 '선형'이 의미하는 것은 무엇인가?   
[링크](https://brunch.co.kr/@gimmesilver/18)   
~~~
1. 선형은 1차 다항식만을 의미하는 것이 아니다.
2. 선형과 비선형
~~~

***

### 2. 활성화 함수(Activation Function)
[링크](https://m.blog.naver.com/worb1605/2211879498281)   
~~~
활성화 함수란 무엇인가?
활성화 함수의 사용하는 이유
~~~
 
***

### 3. 모수, 큰 수의 법칙, 그리고 중심극한정리
[링크](https://chukycheese.github.io/data%20science/parameter-clt/)   
~~~
모수 (Parameter)
큰 수의 법칙 (Law of Large Numbers)
중심극한정리 (Central Limit Theorem)
~~~
 
***

### 4. Gradient Descent (경사하강법)
[링크](https://angeloyeo.github.io/2020/08/16/gradient_descent.html)   
~~~
Gradient Descent (경사하강법)
~~~
 
***

### 5. 연속확률분포에서 확률 밀도함수가 가지는 의미
[링크](https://velog.io/@groovallstar/%ED%99%95%EB%A5%A0-%EB%B6%84%ED%8F%AC-%ED%95%A8%EC%88%98%EC%99%80-%ED%99%95%EB%A5%A0-%EB%B0%80%EB%8F%84-%ED%95%A8%EC%88%98%EC%9D%98-%EC%9D%98%EB%AF%B8)   
~~~
연속확률분포
확률 밀도함수가 가지는 의미(=왜 적분을 해야하는가?)
~~~
 
***

### 6. 확률질량함수와 확률밀도함수
[링크](https://bskyvision.com/387)   
~~~
이산확률변수 와 연속확률변수
확률질량함수와 확률밀도함수
질량과 밀도의 의미
~~~
 
***

### 7. 역전파 (Backpropagation)
[링크](https://bskyvision.com/718?category=635506)   
~~~
역전파를 통해 딥러닝 모델 학습 방법
~~~
 
***

---
---
